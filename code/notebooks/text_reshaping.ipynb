{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e824e8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "from PyPDF2 import PdfWriter, PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba6af29c-ea8d-49c5-8ac7-685c5e1aed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_material_dir = Path(\"/Users/vigji/code/cainsjb/source_material\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f71b359",
   "metadata": {},
   "source": [
    "#### Renumber pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a1ec210-7674-44f9-8eb4-a6d79a272d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = source_material_dir / \"cains_jawbone.txt\"\n",
    "with open(fname, \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "forced_words = [\"Head\", \"May\"]\n",
    "def extract_ne(quote):\n",
    "    words = word_tokenize(quote, language=\"english\")\n",
    "    sents = sent_tokenize(quote, language=\"english\")\n",
    "    tags = nltk.pos_tag(words)\n",
    "    tree = nltk.ne_chunk(tags, binary=True)\n",
    "    interesting_words = [\" \".join(i[0] for i in t)\n",
    "        for t in tree if hasattr(t, \"label\") and t.label() == \"NE\"] + [w for w in words if w in forced_words]\n",
    "    \n",
    "    interesting_sents = {k: [] for k in interesting_words}\n",
    "    for word in set(interesting_words):\n",
    "        for s in sents:\n",
    "            if word in s:\n",
    "                interesting_sents[word].append(s)\n",
    "    return interesting_words, interesting_sents\n",
    "    #for w in words\n",
    "\n",
    "pages = text.split(\"________________\")\n",
    "\n",
    "# Extract all name entities:\n",
    "all_ne = [extract_ne(page) for page in pages]\n",
    "\n",
    "# Put together occurrencies from all pages:\n",
    "pages_dict = dict()\n",
    "for i, (words, sents) in enumerate(all_ne):\n",
    "    for word in words:\n",
    "        if word in pages_dict.keys():\n",
    "            if sents[word] not in pages_dict[word][\"fragments\"]:\n",
    "                pages_dict[word][\"pages\"].append(i)\n",
    "                pages_dict[word][\"fragments\"].append(sents[word])\n",
    "        else:\n",
    "            pages_dict[word] = dict(pages=[i], fragments=[sents[word]])\n",
    "            \n",
    "k = 0        \n",
    "\n",
    "\n",
    "tosave = \"\"\n",
    "for i, page in enumerate(pages):\n",
    "    tosave += f\"------------------\\n\\n[{i + 1}]\\n\" + page + \"\\n\\n\\n\"\n",
    "    \n",
    "with open(fname.parent / f\"{fname.stem}_renumbered.txt\", \"w\") as f:\n",
    "    f.write(tosave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688b4eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fb4186b",
   "metadata": {},
   "source": [
    "#### Split pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc73012e-c61e-4f49-9025-90eb658055e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputpdf = PdfReader(open(source_material_dir / \"cains_jawbone.pdf\", \"rb\"))\n",
    "\n",
    "for i in range(len(inputpdf.pages)):\n",
    "    output = PdfWriter()\n",
    "    output.add_page(inputpdf.pages[i])\n",
    "    with open(source_material_dir / \"pages\" / f\"page_{i}.pdf\", \"wb\") as outputStream:\n",
    "        output.write(outputStream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3602032a-3d0b-4bf1-b565-8eee7bf128e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_dict[\"Aquarius\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bf9dd0-658e-404b-b302-9d0378425779",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_dict[\"Alexander\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d256ef8-6214-4e9b-b338-3461f6b0586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_dict[\"Head\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34de78cd-50db-4f96-8ae7-06850d829292",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_dict[\"May\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37de06f5-e6ec-4a5c-8081-3d543183e68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages[57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19430e4-bd5b-4143-89be-e23f2d38c3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccc58f5-9dfc-43e8-9719-c37afa9a4c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884b3e2b-88d6-41af-b5eb-5f4b43c7fc91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17651d0-35b8-4bcc-806b-b377a3f5dd1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df94b12a-41ea-43fc-80b4-ae5367b0fcfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eebff3-3085-4ed9-ae7f-d9bc5fe4bf2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f317394d-b22b-4ab2-9a79-b8aedeff6bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(page, language=\"english\")\n",
    "sentencies = sent_tokenize(page, language=\"english\")\n",
    "tags = nltk.pos_tag(words)\n",
    "tree = nltk.ne_chunk(tags, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e112cfe1-9e64-49a2-b6f6-f4237769ef63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in sorted(pages_dict):\n",
    "    pgs, sents = pages_dict[k][\"pages\"], pages_dict[k][\"fragments\"]\n",
    "    if len(set(pgs)) > 1:\n",
    "        print(\"---------\")\n",
    "        print(k)\n",
    "        print([p+1 for p in pgs])\n",
    "        for s in sents:\n",
    "            print(f\"--{s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3c41b3-069e-408a-8cef-7f55eda86b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages[85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab4382-9c15-41b7-8baf-099cdeb83231",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.lower().index(\"fox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fd90c8-e026-40b4-9e99-fa2682bfb84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[3000:5300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f39a5ab-46ae-40b1-9dd0-e01c7aed56d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in sorted(pages_dict):\n",
    "    pages, sents = pages_dict[k][\"pages\"], pages_dict[k][\"fragments\"]\n",
    "    #if len(set(pages)) > 1:\n",
    "    print(\"---------\")\n",
    "    print(k)\n",
    "    print([p+1 for p in pages])\n",
    "    for s in sents:\n",
    "        print(f\"--{s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf867a-858b-4e24-9286-a42d6793de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, pages in pages_dict.items():\n",
    "    print(word, pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b159853a-69e9-4b88-ba1a-0bf6efc9e36c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
